# ğŸ“° Multiclass Text Classification Using LLMs  

## ğŸ“Œ Project Overview  
This project implements **multiclass text classification** of Indonesian sports news articles using **Large Language Models (LLMs)**, specifically **IndoBERT** from Hugging Face Transformers.  

The goal is to automatically classify news articles into 5 categories, while comparing two approaches:  

1. **1-Stage Classification** â†’ directly classifies articles into 5 categories.  
2. **2-Stage Hierarchical Classification** â†’ first distinguishes *football* vs *non-football*, then further classifies football into specific leagues.  

---

## âš™ï¸ Tech Stack  
- Python  
- Hugging Face Transformers (IndoBERT)  
- Scikit-learn  
- Pandas & NumPy  
- Matplotlib / Seaborn (visualization)  

---

## ğŸ—‚ï¸ Dataset  
- News articles scraped from Indonesian media (e.g., Detik, Liputan6).  
- Categories:  
  - ğŸ¸ Non-football sports  
  - âš½ Liga Inggris  
  - ğŸ‡®ğŸ‡© Liga Indonesia  
  - ğŸ‡ªğŸ‡¸ Liga Spanyol  
  - ğŸ‡®ğŸ‡¹ Liga Italia  

---

## ğŸ”¬ Methodology  
1. **Data Collection** â†’ Web scraping & manual labeling.  
2. **Text Preprocessing** â†’ cleansing, tokenization, filtering, lemmatization/stemming.  
3. **Modeling** â†’ Fine-tuned IndoBERT for classification.  
   - Model A: 1-stage, direct classification into 5 classes.  
   - Model B: 2-stage, hierarchical classification.  
4. **Evaluation** â†’ Compared accuracy, precision, recall, and F1-score between both approaches.  

---

## ğŸ“Š Results  
- The **2-stage hierarchical classification** achieved better performance than the direct 1-stage approach.  
- Confusion matrices showed reduced misclassification for football categories.  
- Final model demonstrated improved accuracy and robustness across categories.  
